{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Hierarchical Softmax\n",
    "\n",
    "- $p^w$: 从根结点出发到$w$对应的叶子节点的路径\n",
    "- $l^w$: 路径$p^w$中包含的节点个数\n",
    "- $p_1^w,p_2^w,\\dotsc,p_{l^w}^w$: 路径$p^w$中的$l^w$个节点\n",
    "- $d_2^w,d_3^w,\\dotsc,d_{l^w}^w \\in \\{0,1\\}$: $w$的Huffman编码，0表示左节点\n",
    "- $\\theta_1^w,e\\theta_2^w,\\dotsc,\\theta_{l^w-1}^w \\in \\mathbb{R}^m $: 路径$p^w$ 中非叶子节点对应的向量，$\\theta_j^w$ 表示$p^w$中第$j$个非叶子节点对应的向量.\n",
    "\n",
    "hidden layer\n",
    "\n",
    "$$\n",
    "x_w = \\sum_{i=1}^{2c}v(Context(w)_i) \\in \\mathbb{R}^m\n",
    "$$\n",
    "\n",
    "Loss\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = - \\sum_{w \\in C} \\log  p(w|Context(w))\n",
    "$$\n",
    "where\n",
    "$$\n",
    "p(w|Context(w)) = \\prod_{j=2}^{l^w} p(d_j^w|x_w,\\theta_{j-1}^w)\n",
    "$$\n",
    "and\n",
    "$$\n",
    "p(d_j^w|x_w,\\theta_{j-1}^w) =\n",
    "  \\begin{cases}\n",
    "   \\sigma(x_w^T\\theta_{j-1}^w) & d_j^w = 0 \\\\\n",
    "   \\sigma(x_w^T\\theta_{j-1}^w) & d_j^w = 1\n",
    "  \\end{cases}\n",
    "$$\n",
    "or\n",
    "$$\n",
    "p(d_j^w|x_w,\\theta_{j-1}^w) =\n",
    "   [\\sigma(x_w^T\\theta_{j-1}^w)]^{1-d_j^w}\n",
    "   \\cdot\n",
    "   [\\sigma(x_w^T\\theta_{j-1}^w)]^{d_j^w}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = - \\sum_{w \\in C}\\sum_{j=2}^{l^w} \n",
    "  \\{\n",
    "    ({1-d_j^w}) \\cdot \\log[\\sigma(x_w^T\\theta_{j-1}^w)]\n",
    "    +\n",
    "    {d_j^w} \\cdot \\log[\\sigma(x_w^T\\theta_{j-1}^w)]\n",
    "  \\}\n",
    "$$\n",
    "\n",
    "let\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(w,j) =\n",
    "    - ({1-d_j^w}) \\cdot \\log[\\sigma(x_w^T\\theta_{j-1}^w)]\n",
    "    - {d_j^w} \\cdot \\log[\\sigma(x_w^T\\theta_{j-1}^w)]\n",
    "$$\n",
    "\n",
    "update output -> hidden\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac {\\partial \\mathcal{L}(w,j)} {\\partial \\theta_{j-1}^w}\n",
    "  & =\n",
    "   \\frac{\\partial}{\\partial \\theta_{j-1}^w}\n",
    "   \\{\n",
    "    - ({1-d_j^w}) \\cdot \\log[\\sigma(x_w^T\\theta_{j-1}^w)]\n",
    "    - {d_j^w} \\cdot \\log[\\sigma(x_w^T\\theta_{j-1}^w)]\n",
    "   \\} \\\\\n",
    "  & = \n",
    "    - ({1-d_j^w})[1 - \\sigma(x_w^T\\theta_{j-1}^w)]x_w\n",
    "    + {d_j^w} \\sigma(x_w^T\\theta_{j-1}^w) x_w \\\\\n",
    "  & =\n",
    "    [{d_j^w} + \\sigma(x_w^T\\theta_{j-1}^w) - 1]x_w \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta_{j-1}^w := \\theta_{j-1}^w - \\alpha [{d_j^w} + \\sigma(x_w^T\\theta_{j-1}^w) - 1]x_w \n",
    "$$\n",
    "\n",
    "\n",
    "update hidden -> input\n",
    "\n",
    "$$\n",
    "\\frac {\\partial \\mathcal{L}(w,j)} {\\partial x^w}\n",
    "= [{d_j^w} + \\sigma(x_w^T\\theta_{j-1}^w) - 1] \\theta_{j-1}^w\n",
    "$$\n",
    "\n",
    "$$\n",
    "v(\\tilde{w}) := v(\\tilde{w}) - \\alpha\n",
    "\\sum_{j=2}^{l^w} \\frac {\\partial \\mathcal{L}(w,j)} {\\partial x^w}, \\;\n",
    " \\tilde{w} \\in Context(w)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
